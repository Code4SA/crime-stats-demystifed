{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Notation:\n",
    "- SAL- small area\n",
    "- PP- police precinct\n",
    "- AEA- Albers Equal Area Conic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle, randint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from shapely.geometry import Polygon, Point, MultiPoint, MultiPolygon, LineString, mapping, shape\n",
    "from descartes import PolygonPatch\n",
    "import random\n",
    "import fiona\n",
    "import numpy as np\n",
    "import csv\n",
    "from fiona import collection\n",
    "\n",
    "import geopandas as gpd\n",
    "from geopandas.tools import sjoin # rtree index in-build, used with inner, intersection\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def sjoin(left_df, right_df, how='inner', op='intersects',\n",
    "          lsuffix='left', rsuffix='right', **kwargs):\n",
    "    \"\"\"Spatial join of two GeoDataFrames.\n",
    "    left_df, right_df are GeoDataFrames\n",
    "    how: type of join\n",
    "        left -> use keys from left_df; retain only left_df geometry column\n",
    "        right -> use keys from right_df; retain only right_df geometry column\n",
    "        inner -> use intersection of keys from both dfs;\n",
    "                 retain only left_df geometry column\n",
    "    op: binary predicate {'intersects', 'contains', 'within'}\n",
    "        see http://toblerity.org/shapely/manual.html#binary-predicates\n",
    "    lsuffix: suffix to apply to overlapping column names (left GeoDataFrame)\n",
    "    rsuffix: suffix to apply to overlapping column names (right GeoDataFrame)\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_intersections(o):\n",
    "    \n",
    "    from collections import defaultdict\n",
    "\n",
    "    paired_ind = [o.pp_index, o.sal_index]\n",
    "\n",
    "    d_over_ind = defaultdict(list)\n",
    "\n",
    "    # creating a dictionary that has prescints as keys and associated small areas as values\n",
    "    for i in range(len(paired_ind[0].values)):\n",
    "        if not paired_ind[0].values[i]==paired_ind[1].values[i]: # it shows itself as intersection\n",
    "            d_over_ind[paired_ind[0].values[i]].append(paired_ind[1].values[i])\n",
    "\n",
    "    # get rid of the pol precincts with no small areas associated to them- not the most efficient way\n",
    "    d_temp = {}\n",
    "    for l in d_over_ind:\n",
    "        if len(d_over_ind[l]):\n",
    "            d_temp[l] = d_over_ind[l]\n",
    "\n",
    "    return d_temp\n",
    "    \n",
    "    \n",
    "def calculate_join_indices(g1_reind, g2_reind):\n",
    "\n",
    "        # A: region of the police data with criminal record\n",
    "        # C: small area with population data\n",
    "        # we look for all small areas intersecting a given C_i, calculate the fraction of inclusion, scale the\n",
    "        # population accordingly: area(A_j, where A_j crosses C_i)/area(A_j)* popul(A_j)\n",
    "        \n",
    "    \n",
    "        # the actual indexing:\n",
    "        out = sjoin(g1_reind, g2_reind, how =\"inner\", op = \"intersects\")\n",
    "        \n",
    "        out.drop('index_right', axis=1, inplace=True) # there is a double index fo smal areas, so we drop one\n",
    "        #out_sorted = out.sort(columns='polPrecincts_index', ascending=True) # guess sorting is not necessary, cause we are\n",
    "        # using doctionaries at later stages\n",
    "        #dict_over_ind = find_intersections(out_sorted)\n",
    "\n",
    "        # output retains only 1 area (left or right join), and gives no intersection area.\n",
    "        # so we create an array with paired indices: police precincts with associated small areas\n",
    "        # we use it in a loop in a function below\n",
    "        dict_over_ind = find_intersections(out) \n",
    "        \n",
    "        return dict_over_ind\n",
    "    \n",
    "def calculate_inclusion_indices(g1_reind, g2_reind):\n",
    "\n",
    "        out = sjoin(g1_reind, g2_reind, op = \"contains\") ## PP contains SAL\n",
    "        \n",
    "        out.drop('index_right', axis=1, inplace=True) \n",
    "        \n",
    "        dict_over_ind = find_intersections(out) \n",
    "        \n",
    "        return dict_over_ind\n",
    "    \n",
    "def calculate_join(dict_over_ind, g1_reind, g2_reind):\n",
    "        area_total = 0\n",
    "        data_aggreg = []\n",
    "\n",
    "        # note to self: make sure to import shapely Polygon\n",
    "        for index1, crim in g1_reind.iterrows():\n",
    "            try:\n",
    "                index1 = crim.pp_index\n",
    "                sals_found = dict_over_ind[index1]\n",
    "\n",
    "                for sal in range(len(sals_found)):\n",
    "                    pom = g2_reind[g2_reind.sal_index == sals_found[sal]]['geometry']        \n",
    "\n",
    "                    #if pom.intersects(crim['geometry']).values[0]:\n",
    "                    area_int = pom.intersection(crim['geometry']).area.values[0]\n",
    "                    if area_int>0:\n",
    "                        area_total += area_int \n",
    "                        area_crim = crim['geometry'].area\n",
    "\n",
    "                        area_popu = pom.values[0].area\n",
    "\n",
    "                        popu_count = g2_reind[g2_reind.sal_index == sals_found[sal]]['PPL_CNT'].values[0]\n",
    "                        murd_count = crim['murd_cnt']\n",
    "                        pol_province = crim['province']\n",
    "                        popu_frac = (area_int / area_popu) * popu_count# fraction of the pop area contained inside the crim\n",
    "                        #print(popu_frac)\n",
    "                        extra_info_col_names = ['DC_NAME','MN_NAME','MP_NAME','PR_NAME','SP_NAME']\n",
    "                        \n",
    "                        extra_info_col_codes = ['MN_CODE','MP_CODE','PR_CODE','SAL_CODE','SP_CODE']\n",
    "\n",
    "                        extra_names = g2_reind[g2_reind.sal_index == sals_found[sal]][extra_info_col_names]#.filter(regex=(\"NAME\"))\n",
    "                        extra_codes = g2_reind[g2_reind.sal_index == sals_found[sal]][extra_info_col_codes]#.filter(regex=(\"NAME\"))\n",
    "\n",
    "                        data_aggreg.append({'geometry': pom.intersection(crim['geometry']).values[0], 'id1': index1,\\\n",
    "                                      'id2': sals_found[sal] ,'area_pp': area_crim,'area_sal': area_popu,\\\n",
    "                                  'area_inter': area_int, 'popu_inter' : popu_frac, 'popu_sal': popu_count,\\\n",
    "                                  'murd_cnt': murd_count,'province': pol_province,\n",
    "                                  'DC_NAME': extra_names.DC_NAME.values[0],\\\n",
    "                                  'MN_NAME': extra_names.MN_NAME.values[0], 'MP_NAME': extra_names.MP_NAME.values[0],\\\n",
    "                                  'PR_NAME': extra_names.PR_NAME.values[0],'SP_NAME': extra_names.SP_NAME.values[0],\\\n",
    "                                  'MN_CODE': extra_codes.MN_CODE.values[0],'MP_CODE': extra_codes.MP_CODE.values[0],\\\n",
    "                                  'PR_CODE': extra_codes.PR_CODE.values[0],'SAL_CODE': extra_codes.SAL_CODE.values[0],\\\n",
    "                                  'SP_CODE': extra_codes.SP_CODE.values[0]} )\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        df_t = gpd.GeoDataFrame(data_aggreg,columns=['geometry', 'id1','id2','area_pp',\\\n",
    "                                       'area_sal','area_inter', 'popu_inter',\\\n",
    "                                       'popu_sal', 'murd_cnt','province','DC_NAME',\\\n",
    "                                       'MN_NAME','MP_NAME','PR_NAME','SP_NAME',\\\n",
    "                                      'MN_CODE','MP_CODE','PR_CODE','SAL_CODE','SP_CODE'])\n",
    "        #df_t.to_file(out_name)\n",
    "        return df_t, area_total, data_aggreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main functions to find intersection. Files loaded in are the AEA projected shapefiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "salSHP_upd = 'shapefiles/updated/sal_population_aea.shp'\n",
    "polSHP_upd = 'shapefiles/updated/polPrec_murd2015_prov_aea.shp'\n",
    "\n",
    "geo_pol = gpd.GeoDataFrame.from_file(polSHP_upd)\n",
    "geo_sal = gpd.GeoDataFrame.from_file(salSHP_upd)\n",
    "\n",
    "geo_pol_reind = geo_pol.reset_index().rename(columns={'index':'pp_index'})\n",
    "geo_sal_reind = geo_sal.reset_index().rename(columns={'index':'sal_index'})\n",
    "\n",
    "dict_int = calculate_join_indices(geo_pol_reind,geo_sal_reind)\n",
    "print(\"1\")\n",
    "dict_inc = calculate_inclusion_indices(geo_pol_reind, geo_sal_reind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test on a subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt1= geo_pol_reind[geo_pol.province==\"Free State\"].head(n=2)\n",
    "gt2 = geo_sal_reind[geo_sal_reind.PR_NAME==\"Free State\"].reset_index()\n",
    "d = calculate_join_indices(gt1, gt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the intersections on pre-computed indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st 1544.5270484819994\n",
      "2nd 2133.577747626994\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer() \n",
    "\n",
    "df_inc, sum_area_inc, data_inc = calculate_join(dict_inc, geo_pol_reind, geo_sal_reind)\n",
    "end = timer()\n",
    "print(\"1st\", end - start)  \n",
    "\n",
    "start = timer() \n",
    "df_int, sum_area_int, data_int = calculate_join(dict_int, geo_pol_reind, geo_sal_reind)\n",
    "end = timer()\n",
    "print(\"2nd\", end - start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_inc.to_csv('data/pp_sal_inc_included.csv')\n",
    "df_int.to_csv('data/pp_sal_inc_intersections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_aggreg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index1, crim in gt1.iterrows():\n",
    "    print(index1, crim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find pol precincts within WC boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "za_province = gpd.read_file('za-provinces.topojson',driver='GeoJSON')#.set_index('id')\n",
    "za_province.crs={'init': '27700'}\n",
    "\n",
    "\n",
    "wc_boundary = za_province.ix[8].geometry # WC\n",
    "#pp_WC = geo_pol[geo_pol.geometry.within(wc_boundary)]\n",
    "pp_WC_in = geo_pol[geo_pol.geometry.intersects(wc_boundary)]\n",
    "#.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp_WC_overlaps = pp_WC_in[pp_WC_in.province!=\"Western Cape\"]\n",
    "pp_WC_pol_annot = pp_WC_in[pp_WC_in.province==\"Western Cape\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pp_test = pp_WC_in[pp_WC_in['compnt_nm'].isin(['atlantis','philadelphia','kraaifontein','brackenfell','kuilsriver','kleinvleveerste river','macassar','somerset west','fish hoek'])]\n",
    "#pp_test = pp_WC_in[pp_WC_in['compnt_nm'].isin(['beaufort west','doring bay','murraysburg', 'strandfontein','nuwerus','lutzville'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pp_WC_overlaps.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sal_wc_union_bound = sal_WC_in.unary_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare, we load the data without AEA projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_int2 =gpd.GeoDataFrame.from_file('data/intersection_int_ext.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_int2.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_final_col(df_temp):\n",
    "    # add population data per police percinct to the main table\n",
    "    # id1- PP, id2 - SAL\n",
    "    temp = df_int.groupby(by=['id1'])['popu_inter'].sum().reset_index()\n",
    "\n",
    "    data_with_population = pd.merge(df_int, temp, on='id1', how='outer')\\\n",
    "            .rename(columns={'popu_inter_y':'popu_inter_per_pp', 'popu_inter_x':'popu_inter'})\n",
    "\n",
    "    # finally, update the murder rate per SAL : id2 is sal's id    \n",
    "\n",
    "    data_with_population['murd_est_per_int'] = data_with_population['popu_inter']/data_with_population['popu_frac_per_pp']\\\n",
    "               * data_with_population['murd_cnt']\n",
    "    data_mur_per_int = data_with_population.groupby(by=['id2'])['murd_est_per_int'].sum().reset_index()\n",
    "\n",
    "    data_mur_per_sal = data_mur_per_int.rename(columns={'murd_est_per_int':'murd_est_per_sal'})\n",
    "\n",
    "    data_with_population['ratio_per_int'] = data_with_population['popu_inter']/data_with_population['popu_frac_per_pp']\\\n",
    "\n",
    "    data_complete = pd.merge(data_with_population, data_mur_per_sal, on='id2', how='outer')\\\n",
    "            .rename(columns={'id1':'index_PP', 'id2':'index_SAL'})\n",
    "    return data_complete\n",
    "\n",
    "# the geometry can be simplified using Line Simpl. algorithms\n",
    "# data_with_pop['geo_simplified'] = data_with_pop.geometry.simplify(1000)\n",
    "# for use one switches to a chosen simplified geometry:\n",
    "# data_with_pop.set_geometry('geo_simplified', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfFS = df[df.PR_NAME==\"Free State\"]\n",
    "dfoFS = df_int2[df_int2.PR_NAME==\"Free State\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfoFS[dfoFS.id1 == 0]['popu_frac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfFS[dfFS.id1 == 0]['popu_frac'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_int2.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_full_nonpr = compute_final_col(df_int2)\n",
    "data_full_aea = compute_final_col(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_prov = data_full_aea[['PR_NAME','province','murd_est_per_int']]\n",
    "data_prov.groupby('province')['murd_est_per_int'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_prov.groupby('PR_NAME')['murd_est_per_int'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_prov2 = data_full_nonpr[['PR_NAME','province','murd_est_per_int']]\n",
    "data_prov2.groupby('PR_NAME')['murd_est_per_int'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check over small areas\n",
    "pom = {}\n",
    "for ind, row in data_full.iterrows():\n",
    "    pom[row['index_SAL']] = row['murd_est_per_sal'] \n",
    "s=0\n",
    "for key in pom:\n",
    "    s = s + pom[key]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "#wc.plot(ax=ax, color='grey', linewidth=0)\n",
    "#gpd.plotting.plot_multipolygon(ax, sal_wc_union_bound, facecolor='green')\n",
    "\n",
    "#gpd.plotting.plot_multipolygon(ax, sal_wc_union, facecolor='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "gpd.plotting.plot_multipolygon(ax, pp_WC_overlaps.unary_union, facecolor='red')\n",
    "wc.plot(ax=ax, color='black', linewidth=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_full[data_full.MN_NAME==\"City of Cape Town\"]['murd_est_per_int'].sum()\n",
    "data_full_aea[data_full.PR_NAME==\"Free State\"]['murd_est_per_int'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_full_nonpr[data_full.PR_NAME==\"Free State\"]['murd_est_per_int'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_full_aea.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_full_nonpr.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(data_full.MN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wardsShp =gpd.GeoDataFrame.from_file('../wards_delimitation/Wards_demarc/Wards2011.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wardsShp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wardsShp.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
